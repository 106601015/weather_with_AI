{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "house_prices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TekWXpUu-Xpx",
        "outputId": "e12c7d16-bf1f-4664-b4ee-7950b1995507"
      },
      "source": [
        "!pip install pretty_errors\r\n",
        "!pip install catboost\r\n",
        "!pip install lightgbm\r\n",
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pretty_errors in /usr/local/lib/python3.6/dist-packages (1.2.19)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from pretty_errors) (0.4.4)\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n",
            "     |████████████████████████████████| 65.8MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.4\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.19.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (1.0.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzTQLNL5tgvI"
      },
      "source": [
        "# **分為import部分、資料處理部分、封裝AI模型部分、tensorflow dnn模型部分以及主程式**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZNJttLmtjd_"
      },
      "source": [
        "詳細程式碼內容可看註解說明"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HAR4MgW9qTD"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import pretty_errors\r\n",
        "from time import process_time\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.neural_network import MLPRegressor\r\n",
        "# multi-layer Perceptron regressor\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "# random regression\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "# gradient Boosting for regression\r\n",
        "from catboost import CatBoostRegressor\r\n",
        "# gradient boosting on decision trees\r\n",
        "from lightgbm import LGBMRegressor\r\n",
        "# leaf-wise gradient boosting model\r\n",
        "from xgboost import XGBRegressor\r\n",
        "# extreme gradient boosting\r\n",
        "from sklearn.svm import SVR\r\n",
        "# support vector regression\r\n",
        "from sklearn.linear_model import Lasso\r\n",
        "# Lasso\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "# Random Forest\r\n",
        "from mlxtend.regressor import StackingCVRegressor\r\n",
        "# StackingCV, no used\r\n",
        "\r\n",
        "data_path = '/content/drive/My Drive/天氣AI/end_term/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCMXln-691xC"
      },
      "source": [
        "# Deal with house_prices_data\r\n",
        "def house_prices_data_deal():\r\n",
        "    # Create train/test dataset(data:without SalePrice, label:SalePrice)\r\n",
        "    try:\r\n",
        "        test_data = pd.read_csv(os.path.join(data_path, 'test.csv'))\r\n",
        "        train_data = pd.read_csv(os.path.join(data_path, 'train.csv'))\r\n",
        "    except FileNotFoundError:\r\n",
        "        test_data = pd.read_csv(os.path.join(data_path, 'house_prices', 'test.csv'))\r\n",
        "        train_data = pd.read_csv(os.path.join(data_path, 'house_prices', 'train.csv'))\r\n",
        "    train_label = train_data['SalePrice']\r\n",
        "    train_data = train_data.drop('SalePrice', axis=1)\r\n",
        "\r\n",
        "    # Calculate dataset's nullcolumns number, and record in NANColumns list\r\n",
        "    NANColumns = []\r\n",
        "    i = 0\r\n",
        "    for a in test_data.isnull().sum():\r\n",
        "        # if this column has null values\r\n",
        "        if a != 0:\r\n",
        "            print(test_data.columns[i], 'loss {} values'.format(a))\r\n",
        "            NANColumns.append(test_data.columns[i])\r\n",
        "        i += 1\r\n",
        "    print()\r\n",
        "    print('test_data have {} columns'.format(i))\r\n",
        "    print('but {} columns have null values'.format(len(NANColumns)))\r\n",
        "\r\n",
        "    # Handmade classification\r\n",
        "    num_list = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\r\n",
        "                'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath',\r\n",
        "                'FullBath', 'HalfBath', 'Bedroom', 'Kitchen', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea',\r\n",
        "                'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea']\r\n",
        "    str_list = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\r\n",
        "                'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterQual',\r\n",
        "                'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\r\n",
        "                'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\r\n",
        "                'PavedDrive', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\r\n",
        "    drop_list = ['Id', 'Alley', 'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType', 'FireplaceQu']\r\n",
        "    #Id/MasVnrType useless, Alley/PoolQC/Fence/MiscFeature/FireplaceQu too many loss\r\n",
        "\r\n",
        "    # Replace NA value to mean/'X', and drop some columns\r\n",
        "    print('begin replace null values:')\r\n",
        "    print('---num gogo---')\r\n",
        "    for num_name in num_list:\r\n",
        "        print('{} ok'.format(num_name))\r\n",
        "        if num_name in NANColumns:\r\n",
        "            train_data[num_name] = train_data[num_name].replace(np.nan, np.mean(train_data[num_name]))\r\n",
        "            test_data[num_name] = test_data[num_name].replace(np.nan, np.mean(test_data[num_name]))\r\n",
        "    print('---str gogo---')\r\n",
        "    for str_name in str_list:\r\n",
        "        print('{} ok'.format(str_name))\r\n",
        "        if str_name in NANColumns:\r\n",
        "            train_data[str_name] = train_data[str_name].replace(np.nan, \"X\")\r\n",
        "            test_data[str_name] = test_data[str_name].replace(np.nan, \"X\")\r\n",
        "    print('---drop gogo---')\r\n",
        "    for drop_name in drop_list:\r\n",
        "        print('{} ok'.format(drop_name))\r\n",
        "        if drop_name in NANColumns:\r\n",
        "            train_data = train_data.drop(columns=[drop_name])\r\n",
        "            test_data = test_data.drop(columns=[drop_name])\r\n",
        "\r\n",
        "    # Split dataset and label, create complete/trainpart/crosspart data/label\r\n",
        "    split_num = 1200\r\n",
        "    all_num = 1460\r\n",
        "    train_data_complete = train_data\r\n",
        "    train_data_trainpart = train_data[0:split_num]\r\n",
        "    train_data_crosspart = train_data[split_num:all_num] ############ train_data should train_data_trainpart\r\n",
        "    train_label_complete = train_label\r\n",
        "    train_label_trainpart = train_label[0:split_num]\r\n",
        "    train_label_crosspart = train_label[split_num:all_num]\r\n",
        "\r\n",
        "    # Encoding, In order to distinguish numeric and categorical columns\r\n",
        "    CATEGORICAL_COLUMNS =[]\r\n",
        "    NUMERIC_COLUMNS =[]\r\n",
        "    i = 0\r\n",
        "    for a in train_data.dtypes:\r\n",
        "        if a == float or a == int:\r\n",
        "            NUMERIC_COLUMNS.append(train_data.columns[i])\r\n",
        "        elif a == object:\r\n",
        "            CATEGORICAL_COLUMNS.append(train_data.columns[i])\r\n",
        "        i += 1\r\n",
        "\r\n",
        "    le = LabelEncoder()\r\n",
        "    train_data_complete[CATEGORICAL_COLUMNS]    = train_data_complete[CATEGORICAL_COLUMNS].apply(lambda col: le.fit_transform(col))\r\n",
        "    train_data_trainpart[CATEGORICAL_COLUMNS]   = train_data_trainpart[CATEGORICAL_COLUMNS].apply(lambda col: le.fit_transform(col))\r\n",
        "    train_data_crosspart[CATEGORICAL_COLUMNS]   = train_data_crosspart[CATEGORICAL_COLUMNS].apply(lambda col: le.fit_transform(col)) #SettingWithCopyWarning\r\n",
        "    test_data[CATEGORICAL_COLUMNS]              = test_data[CATEGORICAL_COLUMNS].apply(lambda col: le.fit_transform(col))\r\n",
        "\r\n",
        "    return train_data_complete, train_label_complete, train_data_trainpart, train_label_trainpart, train_data_crosspart, train_label_crosspart, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYmnlNzf992h"
      },
      "source": [
        "# AI model fit, evaluate, predict store to csv\r\n",
        "def package_ai(train_data_complete, train_label_complete, train_data_crosspart, train_label_crosspart, test_data, model, model_name):\r\n",
        "    model.fit(train_data_complete, train_label_complete)\r\n",
        "    print(\"Result of {} is {}\".format(model_name, model.score(train_data_crosspart, train_label_crosspart)))\r\n",
        "\r\n",
        "    # Output\r\n",
        "    predicted_prices_list = []\r\n",
        "    for predicted_prices in model.predict(test_data):\r\n",
        "        predicted_prices_list.append(int(predicted_prices))\r\n",
        "\r\n",
        "    output = pd.DataFrame({'Id':range(1461, 2920), 'SalePrice': predicted_prices_list})\r\n",
        "    output.to_csv(os.path.join(data_path, 'house_prices', '{}_submissions.csv'.format(model_name)), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NE9pEil-CEw"
      },
      "source": [
        "# tensorflow AI model create, compile, fit, evaluate, predict store to csv\r\n",
        "def tensorflow_ai(train_data_complete, train_label_complete, train_data_crosspart, train_label_crosspart, test_data, model_type):\r\n",
        "    model = tf.keras.Sequential()\r\n",
        "    if model_type == 'dnn':\r\n",
        "        model.add(tf.keras.layers.Flatten())\r\n",
        "        model.add(tf.keras.layers.Dense(\r\n",
        "                units = 1,\r\n",
        "                #input_shape = [1,74],\r\n",
        "                kernel_initializer = 'ones',\r\n",
        "                kernel_regularizer = tf.keras.regularizers.L1L2(l1=0, l2=1),\r\n",
        "            )\r\n",
        "        )\r\n",
        "        model.add(tf.keras.layers.Dense(50))\r\n",
        "        model.add(tf.keras.layers.Dense(50))\r\n",
        "        model.add(tf.keras.layers.Dense(50))\r\n",
        "        model.add(tf.keras.layers.Dense(25))\r\n",
        "        model.add(tf.keras.layers.Dense(10))\r\n",
        "        model.add(tf.keras.layers.Dense(1))\r\n",
        "    elif model_type == 'cnn':\r\n",
        "        model.add(tf.keras.layers.Flatten())\r\n",
        "        model.add(tf.keras.layers.Dense(50))\r\n",
        "        model.add(tf.keras.layers.Dense(25))\r\n",
        "        model.add(tf.keras.layers.Dense(10))\r\n",
        "        model.add(tf.keras.layers.Dense(1))\r\n",
        "\r\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\r\n",
        "    model.compile(optimizer=opt, loss='mae')\r\n",
        "    train_history = model.fit(train_data_complete.values, train_label_complete.values, batch_size=8, epochs=20)\r\n",
        "\r\n",
        "    model.summary()\r\n",
        "    #acc = train_history.history['acc']\r\n",
        "    #val_acc = train_history.history['val_acc']\r\n",
        "    loss = train_history.history['loss']\r\n",
        "    #val_loss = train_history.history['val_loss']\r\n",
        "\r\n",
        "    epochs = range(1, len(loss)+1)\r\n",
        "    '''\r\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\r\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\r\n",
        "    plt.title('Training and validation accuracy')\r\n",
        "    plt.legend()\r\n",
        "    plt.figure()\r\n",
        "    '''\r\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "    #plt.plot(epochs, val_loss, 'b', label='validation loss')\r\n",
        "    plt.title('Training loss')\r\n",
        "    plt.legend()\r\n",
        "    plt.savefig(os.path.join(data_path, 'house_prices', '{} loss'.format(model_type)))\r\n",
        "    plt.close()\r\n",
        "\r\n",
        "    #print(\"Result of tensorflow_ai is {}\".format(model.score(train_data_crosspart, train_label_crosspart)))\r\n",
        "    print('tensorflow_ai evaluate:', model.evaluate(train_data_crosspart.values, train_label_crosspart.values))\r\n",
        "\r\n",
        "    # Output\r\n",
        "    predicted_prices_list = []\r\n",
        "    for predicted_prices in model.predict(test_data):\r\n",
        "        predicted_prices_list.append(int(predicted_prices))\r\n",
        "\r\n",
        "    output = pd.DataFrame({'Id':range(1461, 2920), 'SalePrice': predicted_prices_list})\r\n",
        "    output.to_csv(os.path.join(data_path, 'house_prices', 'tensorflow_ai_{}_submissions.csv'.format(model_type)), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "2lI48m95-Gzw",
        "outputId": "c8b29020-69aa-49e3-cdd5-86dfcd6fcbcc"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    td, tl, tdt, tlt, tdc, tlc, test_data = house_prices_data_deal()\r\n",
        "\r\n",
        "    # package_ai\r\n",
        "    ai_model_routing = {\r\n",
        "        'mlp' : MLPRegressor(random_state=1, hidden_layer_sizes=(400,1), max_iter=400),\r\n",
        "        'GReg' : GradientBoostingRegressor(random_state=0),\r\n",
        "        'CAT' : CatBoostRegressor(verbose=0, loss_function='RMSE'), #iterations=10, learning_rate=0.03, loss_function='MAE', n_estimators=300, verbose=0\r\n",
        "        'LGMB' : LGBMRegressor(),\r\n",
        "        'XGBRegressor' : XGBRegressor(objective='reg:squarederror'),\r\n",
        "        'svr' : SVR(kernel='linear'),\r\n",
        "        'lasso' : Lasso(),\r\n",
        "        'rf' : RandomForestRegressor(n_estimators=5, random_state=42),\r\n",
        "    }\r\n",
        "    '''\r\n",
        "    ai_model_routing['stack'] = StackingCVRegressor(regressors=(\r\n",
        "                      #ai_model_routing['mlp'],\r\n",
        "                      #ai_model_routing['GReg'],\r\n",
        "                      ai_model_routing['CAT'],\r\n",
        "                      #ai_model_routing['LGMB'],\r\n",
        "                      #ai_model_routing['XGBRegressor'],\r\n",
        "                      #ai_model_routing['svr'],\r\n",
        "                      #ai_model_routing['lasso'],\r\n",
        "                      ai_model_routing['rf'],\r\n",
        "                      ),\r\n",
        "                    meta_regressor=ai_model_routing['lasso'],\r\n",
        "                    )\r\n",
        "    '''\r\n",
        "    for model_name, model in ai_model_routing.items():\r\n",
        "        start = process_time()\r\n",
        "        package_ai(td, tl, tdc, tlc, test_data, model, model_name)\r\n",
        "        end = process_time()\r\n",
        "        print('{} spent time:'.format(model_name), end-start)\r\n",
        "        print()\r\n",
        "\r\n",
        "    # tensorflow_ai\r\n",
        "    start = process_time()\r\n",
        "    tensorflow_ai(td, tl, tdc, tlc, test_data, model_type='dnn')\r\n",
        "    end = process_time()\r\n",
        "    print('tensorflow_ai spent time:', end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-aabc34a27cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhouse_prices_data_deal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# package_ai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ai_model_routing = {\n",
            "\u001b[0;31mNameError\u001b[0m: name 'house_prices_data_deal' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djv121bku7jp"
      },
      "source": [
        "----------------------------------\r\n",
        "這邊用的模型有："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GQV9tx1u9Bf"
      },
      "source": [
        "    # package_ai\r\n",
        "    ai_model_routing = {\r\n",
        "        'mlp' : MLPRegressor(random_state=1, hidden_layer_sizes=(400,1), max_iter=400),\r\n",
        "        'GReg' : GradientBoostingRegressor(random_state=0),\r\n",
        "        'CAT' : CatBoostRegressor(verbose=0, loss_function='RMSE'), #iterations=10, learning_rate=0.03, loss_function='MAE', n_estimators=300, verbose=0\r\n",
        "        'LGMB' : LGBMRegressor(),\r\n",
        "        'XGBRegressor' : XGBRegressor(objective='reg:squarederror'),\r\n",
        "        'svr' : SVR(kernel='linear'),\r\n",
        "        'lasso' : Lasso(),\r\n",
        "        'rf' : RandomForestRegressor(n_estimators=5, random_state=42),\r\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-74hi81u9Z0"
      },
      "source": [
        "最後是CatBoostRegressor的結果最好\r\n",
        "\r\n",
        "(kaggle Score為0.12658，為public第1296名/5360參賽者)\r\n",
        "\r\n",
        "超參數：verbose=0, loss_function='RMSE'"
      ]
    }
  ]
}